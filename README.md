# Scrapy  Books
This project contains examples of spiders that extract data from different websites.

# Requirements

Python 3.8

# Built With

- PyCharm Community Edition 2019.3.3
- Scrapy 1.8.0

# Install

Install Scrapy with:
```sh
pip install Scrapy
```

Install User-Agents with:
```sh
pip install scrapy-user-agents
```

# Spiders
1. Navigate into `amzbooks` folder.
```sh
cd amazbooks
```

2. Make  spider(e.g info) start crawling using  the following command in PyCharm's terminal :

```sh
scrapy crawl info
```

# Disclaimer
Always respect the policy of the website and the restrictions of robots.txt.
Change the USER_AGENT variable in settings.py to real user-agent or  a random one usings User-Agents library.
The project and the information collected is intended only for educational purpose. It is completely open source and has no value intentions to commercialise complete or any part of the same. The developer is on no part the owner of any resources used and does not claim to hold the permissions to use the project.

